---
title: "Projekt Speed Dating"
author: "Fran Canjuga, Gašpar Haramija, Leon Hegedić, Josipa Markić"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lmtest)
library(sjPlot)
library(sjlabelled)
library(sjmisc)
library(ggplot2)


```

## Uvod

U ovom projektnom zadatku, naziva Speed Dating, analizirat ćemo skup podataka prikupljen između 2002. i 2004. godine u sklopu kolegija Statistička analiza podataka na Fakultetu elektrotehnike i računarstva. Dostupni su dva skupa podataka, a analizirat ćemo ih pomoću deskriptivne statistike i inferencijalne analize kako bismo dobili dublji uvid u ponašanje sudionika i međuodnose varijabli.

Ciljevi ovog projekta su upoznavanje s dostupnim podacima o sudionicima i spojevima te izvlačenje relevantnih informacija pomoću deskriptivne statistike i inferencijalne analize. Paralelno s analizom, planiramo unaprijediti svoje razumijevanje osnovnih metodologija statističke analize podataka i praktičnu primjenu programskog jezika R što ćemo primijeniti na sljedećim hipotezama na temelju kojih ćemo izvući zaključke:

1. Je li inteligencija partnera ispitanicima važnija od izgleda?
2. Postoji li razlika u interesu za gaming prema zanimanju sudionika?
3. Možemo li temeljem drugih varijabli predvidjeti hoće li se sudioniku svidjeti partner?

Počet ćemo s analizom deskriptivne statistike kako bismo stekli osnovni uvid u varijable poput starosti, spola, zanimanja i ocjena partnera. Nakon toga, primijenit ćemo inferencijalnu analizu kako bismo istražili postavljene hipoteze, uključujući pitanja o važnosti inteligencije partnera u odnosu na izgled te razlike u interesu za gaming prema zanimanju sudionika.

Ovaj projekt ima značajnost iz perspektive studenata, poput nas samih, jer nam pruža priliku primijeniti stečeno znanje o statističkoj analizi podataka u stvarnom svijetu. Uvid u ovakav skup podataka može pomoći studentima u donošenju informiranih odluka u svakodnevnom životu, bilo da se radi o razumijevanju međuljudskih odnosa ili donošenju odluka temeljenih na vlastitim preferencijama.

## Učitavanje i prikaz podataka

```{r}
participants = read.csv("participant_data.csv")
dates = read.csv("speed_date_data.csv")
head(participants)
head(dates)
```
Na temelju podataka vidimo da je set podataka za participante sadrži 40 stupaca dok za podatke o spojevima sadrži 19.  

Tu se može izbaciti stupce koji nisu uopće potrebni u analizi jer se iz njih ne moze nist zaključiti. Osim toga možemo tu raditi pomoćne datasetove koji će se koristiti u određenim analizama, npr. priprema podataka za linearnu regresiju. 

Osim toga promijeniti klase nekih varijabla koje nisu tocne u pocetnim datasetovima...npr. spol mozemo pretvoriti u numericku ako je lakse, "importance_same_race" je klasa character (nije mi jasno zakaj)

U dates data frameu ima dosta podataka koji su NA, odluciti kaj tocno napraviti s njima

## Deskriptivna Statistika

```{r}
# Osnovna deskriptivna statistika:
summary(participants)
summary(dates)
```
Čišćenje dataset:

Nepostojeće vrijednosti:
```{r}
# sum(is.na(dates$attractive_o))
# sum(is.na(dates$sincere_o))
# sum(is.na(dates$intelligence_o))
# sum(is.na(dates$funny_o))
# sum(is.na(dates$ambitious_o))
# sum(is.na(dates$shared_interests_o))
# sum(is.na(dates$attractive_partner))
# sum(is.na(dates$sincere_partner))
# sum(is.na(dates$intelligence_partner))
# sum(is.na(dates$funny_partner))
# sum(is.na(dates$ambition_partner))
# sum(is.na(dates$shared_interests_partner))
# sum(is.na(dates$like))
# sum(is.na(dates$guess_prob_liked))
# sum(is.na(dates$met))
# sum(is.na(dates$decision))

na_count_per_column <- sapply(dates, function(x) sum(is.na(x)))
data.frame(Column = names(na_count_per_column), NA_Count = na_count_per_column)
dates[!complete.cases(dates),]
```

```{r}
columns_of_interest <- c("attractive_o", "sincere_o", "intelligence_o", "funny_o", "ambitious_o", "shared_interests_o",
                         "attractive_partner", "sincere_partner", "intelligence_partner", "funny_partner",
                         "ambition_partner", "shared_interests_partner", "like", "guess_prob_liked", "met")
threshold <- length(columns_of_interest) / 2
partially_filtered_dates <- dates[rowSums(is.na(dates[, columns_of_interest])) <= threshold, ]
partially_filtered_dates

```

````{r}
partially_filtered_dates[, columns_of_interest] <- lapply(partially_filtered_dates[, columns_of_interest, drop = FALSE], function(x) {
  median_value <- median(x, na.rm = TRUE)
  x[is.na(x)] <- median_value
  return(x)
})

filtered_dates <- partially_filtered_dates
filtered_dates

````

Stršeće vrijednosti
```{r}
boxplots <- lapply(columns_of_interest, function(column_name) {
  boxplot(filtered_dates[[column_name]], main = column_name)
})

```
```{r}
filtered_dates$met[filtered_dates$met > 1] <- 1

unique(filtered_dates$met)
```
Na temelju predefiniranih hipoteza možemo zaključiti da svi stupci u podatcima nisu jednako relevantni. U slučaju analize je li inteligencija partnera važnija od fizičkog izgleda od najveće su važnosti podaci vezani uz inteligenciju i fizički izgled. Analogno za analizu povezanosti gaminga i zanimanja participanta najvažniji su podaci vezani uz gaming i samo područje zanimanja participanta.

#TODO:tu ide prikaz podataka koji su relevantni, vizualizacija istih...histogram, scatter plot, box plot
Promotrimo relevantne varijable koje ćemo kasnije koristiti u istraživačkim pitanjima.
U vezi prvog pitanja bitni su nam inteligencija i fizički izgled partnera.

### Je li inteligencija partnera ispitanicima važnija od izgleda?

Za ovo pitanje su nam bitni podaci o važnosti izgleda, odnosno inteligencije kod ispitanika.
Prvo ćemo izvaditi sve null vrijednosti iz podataka.
```{r}
cleaned_intelligence <- na.omit(participants$intelligence_important)
cleaned_attractiveness <- na.omit(participants$attractive_important)
```

Te ćemo te podatke prikazati uz pomoć histograma.

```{r, fig.width = 14, fig.height=5}
hist(na.omit(participants$intelligence_important), main='Značajnost inteligenciju kod partnera', xlab='Intelligence', ylab='Frequency')
hist(na.omit(participants$attractive_important), main='Značajnost privlačnosti kod partnera', xlab='Attractiveness', ylab='Frequency')
```
Možemo vidjeti da je kod večine ljudi inteligencija bitnija od izgleda kod partnera.

Podatke koje ćemo također analizirati su ocjene partnerove inteligencije i izgleda nakon speed datinga.
```{r,fig.width = 14, fig.height=5}
hist(dates$intelligence_o,main='Ocjena inteligencije', xlab='Inteligence grade', ylab='Frequency')
hist(dates$attractive_o,main='Ocjena izgleda', xlab='Attractivnes grade', ylab='Frequency')
```
Podatke o važnosti atraktivnosti i inteligencije ćemo usporediti u histogramu.
```{r}
merged_data <- inner_join(participants, dates, by = c("id" = "participant_id"))

b <- seq(0, 100, by = 5)

h1 <- hist(na.omit(participants$intelligence_important), breaks = b, plot = FALSE)


h2 <- hist(na.omit(participants$attractive_important), breaks = b, plot = FALSE)

data <- t(cbind(h1$counts, h2$counts))
barplot(data, beside = TRUE, col = c("purple", "lightgreen"), xlab = "Importance", ylab = 'Frequency')
legend("topright",c("intelligence","attractiveness"),fill = c( "purple", "lightgreen"))
```
Normalnost podataka ćemo provjeriti uz pomoć qqplot-ova i testom o jednakosti varijanci.
```{r}
qqnorm(na.omit(participants$attractive_important), pch = 1, frame = FALSE, main = "Važnost izgleda")
qqline(na.omit(participants$attractive_important), col = "blue", lwd = "2")

# QQ plot for intelligence_important without NA values
qqnorm(na.omit(participants$intelligence_important), pch = 1, frame = FALSE, main = "Važnost inteligencije")
qqline(na.omit(participants$intelligence_important), col = "blue", lwd = "2")
```

Uz pretpostavku normalnosti podataka možemo nastaviti testiranje varijanca.

Provest ćemo test o jednakosti varijanci uz pomoć F-testa.
$$F = \frac{S_{X_1}^2 / \sigma_1^2}{S_{X_2}^2 / \sigma_2^2}$$
Pri ćemu za statistike s1 (intelligence_important) i s2 (attractive_important) vrijedi :
$$S_{X_1}^2 = \frac{1}{n_1 - 1} \sum_{i = 1}^{n_1} (X_1^i - \bar{X}_1)^2, \quad S_{X_2}^2 = \frac{1}{n_2 - 1} \sum_{i = 1}^{n_2} (X_2^i - \bar{X}_2)^2.$$
Uz $(n_1 - 1, n_2 - 1)$ stupnjeva slobode.
Hipoteze testa o jednakosti varijanca glase :
$$ \begin{aligned}
H_0&: \sigma_1^2 = \sigma_2^2 \\
H_1&: \sigma_1^2 \neq \sigma_2^2
\end{aligned} $$

Varijanca važnosti izgleda:
```{r}
var_attractive <- var(na.omit(participants$attractive_important))
cat("Varijanca od attractive_important:", var_attractive, "\n")
```
Varijanca važnosti inteligencije:
```{r}
var_intelligence <- var(na.omit(participants$intelligence_important))
cat("Varijanca od intelligence_important:", var_intelligence, "\n")
```
Te radimo F-test:
```{r}
var.test(participants$attractive_important, participants$intelligence_important)
```
Zaključujemo uz p-vrijednost od 2.2e-16 da su te varijance različite. Odbacujemo H0 hipotezu u koristi H1 te ćemo koristiti T-test za dva uzorka uz nejednake varijance. 

T-test za dva auzorka uz nepoznate i nejednake varijance

$$ \begin{aligned}
H_0&: Inteligencija \quad je \quad vaznija\quad od \quad izgleda \\
H_1&: Inteligencija \quad nije \quad važnija \quad od \quad izgleda
\end{aligned} $$
```{r}
t_test_result <- t.test(participants$intelligence_important, 
                        participants$attractive_important, 
                        var.equal = FALSE)

print(t_test_result)
```
Uz malu p-vrijednost od 0.000175 odbacujemo hipotezu H0 u korist H1.



#TODO:za gaming i zaposljenje mozemo napraviti box plot pomocu group by po zaposlenju (za svako zaposlenje novi box plot) 
#scatter plot za inteligenciju i fizicki izgled sa dvije razlicite boje
  
#TODO:trebamo dogovoriti kaj napraviti za trecu hipotezu

## Inferencijalna analiza


Drugo istraživacko pitanje glasi : Postoji li razlika u izbirljivosti prema zanimanju sudionika?

Posljednje istraživačko pitanje : Možemo li temeljem drugih varijabli predvidjeti hoće li speed date biti uspješniji?

Kako bismo vidjeli može li se na temelju ocjena sudionika o njihovim partnerima predvidjeti je li spoj bio uspješan ili ne. Prvo idemo razraditi definiciju uspješnosti spoja. Spoj je usješan jedino ako je sudionik u spoju ocjenio cjelokupno iskustvo s 1, a nuespješan ako je ocjenjeno s 0. Definicija je nužno ovakva jer se može dogoditi situacija ako dvoje ljudi otudu na spoj, jednoj se osobi spoj svidio, a drugoj ne onda njihove ocjene mogu biti drugačije. Zbog toga smo odlučili na ovaj subjektivan pristup. Pošto je odluka za uspješnost spoja binarna, odlučili smo koristiti model logističke regresije. 

Model logističke regresije je statistički model koji se koristi za analizu odnosa između jedne binarne zavisne promenljive varijable i više nezavisnih promenljivih varijabli. Sam model je oblika:

$$\begin{aligned}
F(x'\beta) = \Lambda(x'\beta) = \frac{1}{1 + e^{-x'\beta}}
\end{aligned}$$

Cilj je predviđanje vjerojatnosti da će zavisna promenljiva varijabla imati vrijednost 1 (uspjeh) ili 0 (neuspjeh) na osnovu linearnih kombinacija nezavisnih promenljivih varijabli ugurane u sigmoidalne funkciju. Model logističke regresije ima funkciju vjerodstojnosti:

$$\begin{aligned}
L(\beta) = \prod_{i=1}^{N}(\Lambda(x_i'\beta))^{y_i}(1-\Lambda(x_i'\beta))^{1-y_i}
\end{aligned}$$

ili u log obliku: 

$$\begin{aligned}
l(\beta) = \sum_{i=1}^{N}y_i log(\Lambda(x_i'\beta))+ \sum_{i=1}^{N}(1-y_i)log(1-\Lambda(x_i'\beta))
\end{aligned}$$

Ovaj problem nema konkretno rješenje, ali može se riješiti ili itterativno metodom gradijentnog spusta ili numerički Newton-Raphsonovom metodom. Logistička regresija omogućava interpretaciju utjecaja svake nezavisne vaijable primjenjive na log-odds vjerovatnosti, pružajući također mogućnost procjene vjerojatnosti klasifikacije.

Kako bismo vidjeli snagu ovog modela odlučili smo primjeniti unakrsnu provjeru, koja uvodne podatke na trening_set:testing_set u omjeru 70:30:
````{r}
set.seed(123)  

train_indices <- sample(1:nrow(filtered_dates), 0.7 * nrow(filtered_dates))

training_set <- filtered_dates[train_indices, ]

testing_set <- filtered_dates[-train_indices, ]
````

Kod za učenje i rezultati učenja us vidljivi ovdje:
```{r}

logistic_model <- glm(decision ~ attractive_o + sincere_o + intelligence_o + funny_o + ambitious_o + shared_interests_o + attractive_partner + sincere_partner + intelligence_partner + funny_partner + ambition_partner + shared_interests_partner + like + guess_prob_liked + met, data = training_set, family = "binomial")

summary(logistic_model)
```
Kako bismo odredili preciznost modela, prvo smo odlučili implemetirati ROC krivulju. ROC(Receiver Operating Characteristic) je graf koji ilustrira sposobnost dijagnostičkog modela u binarnoj klasifikaciji na različitim pragovima odlučivanja. Prikazuje odnos između stvarno pozitivnih rezultata (osjetljivosti) i lažno pozitivnih rezultata (1 - specifičnost), pomažući vizualizaciji kompromisa između osjetljivosti i specifičnosti na različitim pragovima. AUC (površina ispod krivulje ROC) mjera je ukupne performanse modela. Što je AUC bliže 1, to je model bolji.

Graf ROC je ovdje:
```{r}
library(pROC)
library(pheatmap)

predictions <- predict(logistic_model, testing_set, type = "response")

# Convert predicted probabilities to binary predictions (0 or 1)
predicted_class <- ifelse(predictions > 0.5, 1, 0)

# Assuming 'response_variable' is the actual response variable in your data
actual_class <- testing_set$decision

# Confusion matrix
conf_matrix <- table(actual_class, predicted_class)

roc_curve <- roc(actual_class, predicted_class)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlab = "Lažno Pozitivni", ylab="Istinito pozitivni")
```

S AUC vrijednosti ispod grafa:
````{r}
# Area under the ROC curve (AUC)
cat("AUC:", auc_value, "\n")
````

Slijedeća performansa koju smo htejli pokazati je Matrica zabune. Matrica zabune je tablica koja prikazuje broj stvarno pozitivnih, stvarno negativnih, lažno pozitivnih i lažno negativnih klasifikacija u kontekstu evaluacije binarnog klasifikacijskog modela, pružajući uvid u performanse modela i vrste pogrešaka koje čini. Ova matrica često služi kao osnova za izračunavanje različitih evaluacijskih mjera, poput preciznosti, osjetljivosti i specifičnosti.

Naša matrica zabune:
````{r}
# Stylish Confusion Matrix using pheatmap
pheatmap(
  conf_matrix,
  main = "Matrica zabune",
  fontsize_row = 12,  # Adjust font size for row labels
  fontsize_col = 12,  # Adjust font size for column labels
  cellwidth = 100,     # Adjust cell width
  cellheight = 100,    # Adjust cell height
  cluster_cols = FALSE,
  cluster_rows = FALSE,
  display_numbers=TRUE,
  color = colorRampPalette(c("blue", "steelblue", "white"))(10),  # Adjust color palette
  show_rownames = TRUE,  # Show row names (actual labels)
  show_colnames = TRUE,  # Show column names (predicted labels)
  angle_col = 0,       # Rotate column names for better visibility
  number_color = "black",  # Color of the text inside cells
  number_format = "%.0f", # Format for the numbers (adjust as needed)
  fontsize_number = 12    # Font size of the numbers inside cells
)

````
Retci matrice prikazuju istinte vrijednosti, dok stupci prikazuju predviđene vrijednosti za model. Polja na dijagonali prikazuju broj točno previđenih primjera, dok polja izvan dijagonale prikazuju broj krivo prediđenih primjera. Kao što se vidi iz našeg modela, ima mnogo točno predviđenih modela, ali i mnogo krivo predviđenih modela, koji će se isto vidjeti u kasnijim metrikama.

Još neke mjere preciznosti:

Točnost: Glavna interpretacija koliko je dobar model. Formula: 
$$
\begin{align}
1) Točnost (Accuracy) = \frac{TP + TN}{FP + FN + TP + TN}
\end{align}
$$
Preciznost: Pokazatelj lažno pozitivnih rezulata. Ključna je metrika kada je pogreška lažne klasifikacija velika. Formula:
$$
\begin{align}
2) Preciznost (Precision)= \frac{TP}{FP + TP}
\end{align}
$$
Osjetljivost: važan kada su troškovi propuštanja pozitivnih slučajeva visoki. Cilj mu je minimizirati lažno negativne rezultate. Formula:
$$
\begin{align}
3) Osjetljivost (Recall)= 
\frac{TP}{TP + FN}
\end{align}
$$
F1: Koristan je kada želite jednu metriku koja uzima u obzir i lažno pozitivne i lažno negativne rezultate. Formula:
$$
\begin{align}
4) F1= 
\frac{2*Precisnost*Osjeltjivost}{Preciznost+Osjetljivost}
\end{align}
$$
gdje su TP(točno pozitivni), FP(lažno pozitivni), TN(točno negativni) i FN(lažno negativni). Vrijednsoti ovih metrika za naš model su prikazane ovdje:
```{r}
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)

# Calculate precision
precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])

# Calculate recall
recall <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

# Calculate F1 score
f1_score <- 2 * (precision * recall) / (precision + recall)

# ROC curve and AUC-ROC
library(pROC)
roc_curve <- roc(actual_class, predictions)
auc_roc <- auc(roc_curve)

cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", f1_score, "\n")
#cat("AUC-ROC:", auc_roc, "\n")
```
Vidimo da su rezultati u redu. Prciznost modela je veća od 75% i većina ostalih parametara je iznad 70%.

Pitanje kojim se nadovezujemo na prethodno: Koje od značajki utječu na model najviše, a koje najmanje?

Gdje vrijednost pojedinog parametra možemo i vidjeti na slijedećem grafu:
````{r}
plot_model(logistic_model, vline.color = "red", transform = NULL, title="Vrijenost parametra za pojedinu značajku")
````
Jasno se vidi da parametri like i atrctive_partner najviše utječu na konačnu mogućnost da model predviđa. Ali mi bismo htjeli da vidimo kojeg regresora bismo potencijalno mogli isključiti iz modela, a kojeg ne a da ne utječemo previše na izlaz modela. Za to ćemo iskoristiti LR test.

LR test (Likelihood Ratio test) je statistički test koji se koristi u kontekstu procjene značajnosti razlika između dvaju modela koji su ugniježdeni jedan u drugi. Test se temelji na usporedbi logaritma vjerodostojnosti (likelihood) modela koji je potpuno specifičan (nula restrikcija) s logaritmom vjerodostojnosti modela koji ima neke restrikcije (npr., postavljanje određenih parametara na nulu). Statistička testna statistika LR testa slijedi distribuciju $\chi$-kvadrat, a p-vrijednost testa pomaže u odlučivanju o odbacivanju nulte hipoteze o tome da su modeli ekvivalentni. 

Prvo što ćemo napraviti je hitpoteze za LR test:
$$
H_0: \beta_g = 0 \\
H_1: \beta_g \neq 0
$$
Sada ćemo ići po svim svim regresorima u originalnom modelu, istrenirati broj modela koji je jednak originalnom broju regresora, ali svaki od tih modela neće imati regresor koji želimo testirati. I vidjeti koilko je li neki regresor redundantan s nivoom značajnosti 0.05. Rezultati su vidljivi u donjoj tablici: 

```{r}
models <- list()

for (col in columns_of_interest) {
  formula <- as.formula(paste("decision ~", paste(columns_of_interest[!columns_of_interest %in% col], collapse = "+")))
  model <- glm(formula, data = training_set, family = "binomial")
  models[[col]] <- model
}

custom_format <- function(x) {
  if (abs(x) >= 0.001) {
    return(sprintf("%.6f", x))
  } else {
    return(format(x, scientific = TRUE))
  }
}

p_values <- numeric(length(columns_of_interest))
i = 1
for(col in columns_of_interest) {
  p_value <- lrtest(logistic_model, models[[col]])$`Pr(>Chisq)`[2]
  #print(p_value)
  p_values[i] <- p_value
  i <- i+1
}

p_values <- data.frame(column = columns_of_interest, p_value = p_values)

p_values <- p_values %>% mutate(p_value = sapply(p_value, custom_format))

p_values
```

Vidimo po rezultatima da su attractive_partner i like najznačajniji parametri, dok intelligance_partner i intelligance_o najneznačajniji za izlaz modela. Što je i očekivano po vrijednostima parametara u originalnom modelu.


Za konačni eksperiment u ovom radu, htjeli smo vidjeti je li moguće poboljšati izlaz modela ako izbacimo regresore koji su zadovoljili LR test. Konačni rezultati su ovdje:

````{r}
logistic_model_better <- glm(decision ~ attractive_o + sincere_o + attractive_partner + sincere_partner + funny_partner + ambition_partner + shared_interests_partner + like + guess_prob_liked, data = training_set, family = "binomial")

logistic_model_better

predictions <- predict(logistic_model_better, testing_set, type = "response")

predicted_class <- ifelse(predictions > 0.5, 1, 0)

# Assuming 'response_variable' is the actual response variable in your data
actual_class <- testing_set$decision

# Confusion matrix
conf_matrix <- table(actual_class, predicted_class)

pheatmap(
  conf_matrix,
  main = "Matrica zabune",
  fontsize_row = 12,  # Adjust font size for row labels
  fontsize_col = 12,  # Adjust font size for column labels
  cellwidth = 100,     # Adjust cell width
  cellheight = 100,    # Adjust cell height
  cluster_cols = FALSE,
  cluster_rows = FALSE,
  display_numbers=TRUE,
  color = colorRampPalette(c("blue", "steelblue", "white"))(10),  # Adjust color palette
  show_rownames = TRUE,  # Show row names (actual labels)
  show_colnames = TRUE,  # Show column names (predicted labels)
  angle_col = 0,       # Rotate column names for better visibility
  number_color = "black",  # Color of the text inside cells
  number_format = "%.0f", # Format for the numbers (adjust as needed)
  fontsize_number = 12    # Font size of the numbers inside cells
)

accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
````
Izbacivanjem smo uspjeli dobiti poboljšanje od 0.2%.
## Zaključak

zakljucak na kraju svega WOHOOO
